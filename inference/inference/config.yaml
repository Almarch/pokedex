llm:
  model: "Qwen/Qwen3-8B-AWQ"
  gpu_memory_utilization: 0.875
  max_model_len: 8192

generate:
  temperature: 0.35
  max_tokens: 1024
  top_p: 0.9
  top_k: 50

rerank:
  batch_size: 4

embed:
  model: "Qwen/Qwen3-Embedding-0.6B"
  gpu: false
  asymmetric: true
  batch_size: 4
  
cache: "/cache"


